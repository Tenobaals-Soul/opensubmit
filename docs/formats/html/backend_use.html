<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Teacher Manual &#8212; OpenSubmit  documentation</title>
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Administrator Manual" href="admin_use.html" />
    <link rel="prev" title="Students Manual" href="frontend_use.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="_static/favicon-32x32.png"></span>
          OpenSubmit</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="about.html">About</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Manuals <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="frontend_use.html">Students Manual</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Teacher Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="admin_use.html">Administrator Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer_use.html">Developer Manual</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Jump to... <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Teacher Manual</a><ul>
<li><a class="reference internal" href="#managing-study-programs">Managing study programs</a></li>
<li><a class="reference internal" href="#managing-courses">Managing courses</a><ul>
<li><a class="reference internal" href="#course-creation">Course creation</a></li>
<li><a class="reference internal" href="#providing-a-link-to-the-course-assignments">Providing a link to the course assignments</a></li>
<li><a class="reference internal" href="#grading-scheme-creation">Grading scheme creation</a></li>
<li><a class="reference internal" href="#assignment-creation">Assignment creation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#managing-submissions">Managing submissions</a><ul>
<li><a class="reference internal" href="#submission-grading">Submission grading</a></li>
<li><a class="reference internal" href="#grading-table">Grading table</a></li>
<li><a class="reference internal" href="#duplicate-report">Duplicate report</a></li>
</ul>
</li>
<li><a class="reference internal" href="#automated-testing-of-submissions">Automated testing of submissions</a><ul>
<li><a class="reference internal" href="#how-to-write-a-test-script">How to write a test script</a></li>
<li><a class="reference internal" href="#test-script-examples">Test script examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#developer-reference">Developer reference</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="teacher-manual">
<h1>Teacher Manual<a class="headerlink" href="#teacher-manual" title="Permalink to this headline">¶</a></h1>
<p>OpenSubmit was invented for making assignments more fun for the students, and less work for the teachers. Before you start to read into details, we recommend to get into the basic <a class="reference internal" href="index.html#index"><span class="std std-ref">idea</span></a> and general <a class="reference internal" href="about.html#principles"><span class="std std-ref">principles</span></a>.</p>
<p>Student tutors, course owners and administrators (see also <a class="reference internal" href="admin_use.html#permissions"><span class="std std-ref">Permissions</span></a>) all operate in the teacher backend, which is reachable by a link at the bottom of the student dashboard page, or directly via <em>&lt;your OpenSubmit url&gt;/teacher</em>.</p>
<div class="section" id="managing-study-programs">
<h2>Managing study programs<a class="headerlink" href="#managing-study-programs" title="Permalink to this headline">¶</a></h2>
<p>Location: <code class="docutils literal"><span class="pre">Teacher</span> <span class="pre">backend</span></code> - <code class="docutils literal"><span class="pre">System</span></code> - <code class="docutils literal"><span class="pre">Actions</span></code> - <code class="docutils literal"><span class="pre">Manage</span> <span class="pre">study</span> <span class="pre">programs</span></code></p>
<p>This function is only available for users with according <a class="reference internal" href="admin_use.html#permissions"><span class="std std-ref">permissions</span></a>.</p>
<p>Students register in OpenSubmit by themselves, simply by using one of the configured authentication methods (see <a class="reference internal" href="admin_use.html#auth"><span class="std std-ref">Authentication methods</span></a>). After the first login, there are asked to complete their user details (see also <a class="reference internal" href="frontend_use.html#userdetails"><span class="std std-ref">Setting your user details</span></a>).</p>
<p>One part of the user details dialogue is the choice of the study program, e.g. <em>computer science (Bachelor)</em> or <em>Greek philosophy (Master)</em>. When more than one study program is configured in OpenSubmit, then this choice becomes mandatory. If only a single or no study program is configured, then the students are not forced to make that choice.</p>
<p>The study program is shown in the <a class="reference internal" href="admin_use.html#useroverview"><span class="std std-ref">User management</span></a> and the <a class="reference internal" href="#gradingtable"><span class="std std-ref">Grading table</span></a>. Is has no further impact on the operation of OpenSubmit, but can help with the grading of mixed courses.</p>
</div>
<div class="section" id="managing-courses">
<h2>Managing courses<a class="headerlink" href="#managing-courses" title="Permalink to this headline">¶</a></h2>
<p>Location: <code class="docutils literal"><span class="pre">Teacher</span> <span class="pre">backend</span></code> - <code class="docutils literal"><span class="pre">System</span></code> - <code class="docutils literal"><span class="pre">Actions</span></code> - <code class="docutils literal"><span class="pre">Manage</span> <span class="pre">courses</span></code></p>
<p>This function is only available for users with according <a class="reference internal" href="admin_use.html#permissions"><span class="std std-ref">permissions</span></a>.</p>
<p>Assignments for students belong to a course. The registered students can choose (see also <a class="reference internal" href="frontend_use.html#usercourses"><span class="std std-ref">Choosing your courses</span></a>) which course they participate in. This is different to many other learning management systems, which offer dedicated course permission systems (see also <a class="reference internal" href="about.html#principles"><span class="std std-ref">The Zen of OpenSubmit</span></a>).</p>
<div class="section" id="course-creation">
<h3>Course creation<a class="headerlink" href="#course-creation" title="Permalink to this headline">¶</a></h3>
<p>Location: <code class="docutils literal"><span class="pre">Teacher</span> <span class="pre">backend</span></code> - <code class="docutils literal"><span class="pre">System</span></code> - <code class="docutils literal"><span class="pre">Actions</span></code> - <code class="docutils literal"><span class="pre">Manage</span> <span class="pre">courses</span></code> - <code class="docutils literal"><span class="pre">Add</span> <span class="pre">course</span></code></p>
<p>The following settings must be configured for a new course:</p>
<dl class="docutils" id="active">
<dt>Title</dt>
<dd>The title of the course.</dd>
<dt>Course owner</dt>
<dd>A user who automatically gets <a class="reference internal" href="admin_use.html#permissions"><span class="std std-ref">course owner</span></a> permissions for this course. His email address is used as sender in student notifications.</dd>
<dt>Tutors</dt>
<dd>A set of users that get <a class="reference internal" href="admin_use.html#permissions"><span class="std std-ref">student tutor</span></a> permissions for this course.</dd>
<dt>Course description link</dt>
<dd>A URL for the course home page. Used in the student dashboard.</dd>
<dt>Active</dt>
<dd>The flag decides if any assignments from this course are shown to the students, regardless of their deadlines. This allows to put courses in an ‘archive’ mode after the term is over.</dd>
<dt>LTI key / LTI passphrase</dt>
<dd><p class="first">OpenSubmit supports the LTI protocol, so that you can integrate it into other learning management systems (LMSs) such as <a class="reference external" href="https://docs.moodle.org/34/en/External_tool">Moodle</a>.</p>
<p>The LMS needs a consumer key and a shared secret resp. passphrase that you configure separately for each OpenSubmit course. This makes sure that the system knows automatically the course in which the external LMS user is interested in. Such users don’t need to perform any authentication, OpenSubmit blindly believes in the identify information forwarded by the LMS. If a user already exists with the same email address, the LMS identity is added to his social login credentials.</p>
<p class="last">Using LTI authentication can lead to duplicate accounts. You can <a class="reference internal" href="admin_use.html#merge-users"><span class="std std-ref">merge users</span></a> to fix that.</p>
</dd>
</dl>
</div>
<div class="section" id="providing-a-link-to-the-course-assignments">
<h3>Providing a link to the course assignments<a class="headerlink" href="#providing-a-link-to-the-course-assignments" title="Permalink to this headline">¶</a></h3>
<p>Location: <code class="docutils literal"><span class="pre">Teacher</span> <span class="pre">backend</span></code> - <code class="docutils literal"><span class="pre">Course</span></code> - <code class="docutils literal"><span class="pre">Info</span></code></p>
<p>After using an <a class="reference internal" href="admin_use.html#auth"><span class="std std-ref">authentication provider</span></a>, students get automatically an account and end up on the student dashboard, where none of the OpenSubmit courses is activated for them. This leads to the fact that they can’t see any course assignments by default.</p>
<p>If you want to make sure that students automatically see the assignments for your course, you need to tell OpenSubmit the course ID when entering the system. This can be done by linking to a course-specific OpenSubmit URL. It is shown in the course details on the teacher backend landing page.</p>
</div>
<div class="section" id="grading-scheme-creation">
<span id="gradingscheme"></span><h3>Grading scheme creation<a class="headerlink" href="#grading-scheme-creation" title="Permalink to this headline">¶</a></h3>
<p>Location: <code class="docutils literal"><span class="pre">Teacher</span> <span class="pre">backend</span></code> - <code class="docutils literal"><span class="pre">System</span></code> - <code class="docutils literal"><span class="pre">Actions</span></code> - <code class="docutils literal"><span class="pre">Manage</span> <span class="pre">grading</span> <span class="pre">schemes</span></code></p>
<p>Before you can create assignments for students, you must think about the grading scheme. A grading scheme is an arbitrary collection of gradings, were each grading either means ‘pass’ or ‘fail’.</p>
<p>Grading schemes can later be used in the creation of assignments.</p>
</div>
<div class="section" id="assignment-creation">
<h3>Assignment creation<a class="headerlink" href="#assignment-creation" title="Permalink to this headline">¶</a></h3>
<p>Location: <code class="docutils literal"><span class="pre">Teacher</span> <span class="pre">backend</span></code> - <code class="docutils literal"><span class="pre">Course</span></code> - <code class="docutils literal"><span class="pre">Actions</span></code> - <code class="docutils literal"><span class="pre">Manage</span> <span class="pre">assignments</span></code> - <code class="docutils literal"><span class="pre">Add</span> <span class="pre">assignment</span></code></p>
<p>With an existing course and an appropriate grading scheme, you can now create a new assignment:</p>
<dl class="docutils">
<dt>Title (mandatory)</dt>
<dd>The title of the assignment.</dd>
<dt>Course (mandatory)</dt>
<dd>The course this assignment belongs to.</dd>
<dt>Grading scheme (optional)</dt>
<dd>The grading scheme for this assignment. If you don’t chose a grading scheme, than this assignment is defined as ungraded, which is also indicated on the student dashboard. Ungraded assignments are still validated.</dd>
<dt>Max authors (mandatory)</dt>
<dd>For single user submissions, set this to one. When you choose larger values, the students get a possiblity to define their co-authors when submitting a solution.</dd>
<dt>Student file upload (mandatory)</dt>
<dd>If students should upload a single file as solution, enable this flag. Otherwise, they can only enter submission notes. Students typically submit archives (ZIP / TGZ) or PDF files, but the system puts no restrictions on this.</dd>
<dt>Description (mandatory)</dt>
<dd>The assignment description is linked on the student dashboard. It can either bei configured as link, f.e. when you host it by yourself, or can be uploaded to OpenSubmit.</dd>
<dt>Publish at (mandatory)</dt>
<dd>The point in time where the assignment becomes visible for students. Users with teacher backend access rights always see the assignment in their student dashboard, so that they can test the validation before the official start.</dd>
<dt>Soft deadline (optional)</dt>
<dd><p class="first">The deadline shown to the students. After this point in time, submission is still possible, although the remaining time counter on the student dashboard shows zero.</p>
<p>If you leave that value empty, then the hard deadline becomes the soft deadline, too.</p>
<p class="last">The separation between hard and soft deadline is intended for the typical late-comers, which try to submit their solution shortly after the deadline. Broken internet, time zone difficulties, dogs eating the homework … we all know the excuses.</p>
</dd>
<dt>Hard deadline (optional)</dt>
<dd><p class="first">The deadline after which submissions for this assignment are no longer possible.</p>
<p class="last">If you leave that value empty, then submissions are possible as long as the course is <a class="reference internal" href="#active"><span class="std std-ref">active</span></a>.</p>
</dd>
<dt>Validation test (optional)</dt>
<dd>The uploaded <a class="reference internal" href="#testing"><span class="std std-ref">validation test</span></a> is executed automatically for each student submission and can lead to different subsequent <a class="reference internal" href="#states"><span class="std std-ref">states</span></a> for the submission. Students are informed about this state change by email. The test is executed before the hard deadline. It is intended to help the students to write a valid solution.</dd>
<dt>Download of validation test (optional)</dt>
<dd>The flag defines if the students should get a link to the <a class="reference internal" href="#testing"><span class="std std-ref">validation test</span></a>. This makes programming for the students much more easy, since the can locally if their uploaded code would pass the validation checks.</dd>
<dt>Full test (optional)</dt>
<dd>The uploaded <a class="reference internal" href="#testing"><span class="std std-ref">full test</span></a> is executed automatically for each student submission and can lead to different subsequent <a class="reference internal" href="#states"><span class="std std-ref">states</span></a> for the submission. Students are <em>not informed</em> about this test. The test is executed after the hard deadline. It is intended to support the teachers in their grading with additional information.</dd>
<dt>Support files (optiona)</dt>
<dd>A set of files that you want to have in the same directory when the <a class="reference internal" href="#testing"><span class="std std-ref">validation test</span></a> or the <a class="reference internal" href="#testing"><span class="std std-ref">full test</span></a> is running.</dd>
<dt>Test machines (mandatory in some cases)</dt>
<dd>When you configure a <a class="reference internal" href="#testing"><span class="std std-ref">validation test</span></a> or <a class="reference internal" href="#testing"><span class="std std-ref">full test</span></a>, you need to specify the :<a class="reference internal" href="admin_use.html#executors"><span class="std std-ref">test machines</span></a> that run it. When chosing multiple machines, the testing load is distributed.</dd>
</dl>
</div>
</div>
<div class="section" id="managing-submissions">
<h2>Managing submissions<a class="headerlink" href="#managing-submissions" title="Permalink to this headline">¶</a></h2>
<p>A submission is a single (archive) file + notes handed in by a student. Every submission belongs to a particular assignment and its according course in OpenSubmit.</p>
<p>A student submission can be in different states. Each of the states is represented in a different way in student frontend and the teacher backend:</p>
<div class="highlight-python" id="states"><div class="highlight"><pre><span></span>    <span class="c1"># State description in teacher backend</span>
    <span class="n">STATES</span> <span class="o">=</span> <span class="p">(</span>

        <span class="c1"># The submission is currently uploaded,</span>
        <span class="c1"># some internal processing still takes place.</span>
        <span class="p">(</span><span class="n">RECEIVED</span><span class="p">,</span> <span class="s1">&#39;Received&#39;</span><span class="p">),</span>

        <span class="c1"># The submission was withdrawn by the student</span>
        <span class="c1"># before the deadline. No further automated action</span>
        <span class="c1"># will take place with this submission.</span>
        <span class="p">(</span><span class="n">WITHDRAWN</span><span class="p">,</span> <span class="s1">&#39;Withdrawn&#39;</span><span class="p">),</span>

        <span class="c1"># The submission is completely uploaded.</span>
        <span class="c1"># If code validation is configured, the state will</span>
        <span class="c1"># directly change to TEST_VALIDITY_PENDING.</span>
        <span class="p">(</span><span class="n">SUBMITTED</span><span class="p">,</span> <span class="s1">&#39;Submitted&#39;</span><span class="p">),</span>

        <span class="c1"># The submission is waiting to be validated with the</span>
        <span class="c1"># validation script on one of the test machines.</span>
        <span class="c1"># The submission remains in this state until some</span>
        <span class="c1"># validation result was sent from the test machines.</span>
        <span class="p">(</span><span class="n">TEST_VALIDITY_PENDING</span><span class="p">,</span> <span class="s1">&#39;Validity test pending&#39;</span><span class="p">),</span>

        <span class="c1"># The validation of the student sources on the</span>
        <span class="c1"># test machine failed. No further automated action will</span>
        <span class="c1"># take place with this submission.</span>
        <span class="c1"># The students get informed by email.</span>
        <span class="p">(</span><span class="n">TEST_VALIDITY_FAILED</span><span class="p">,</span> <span class="s1">&#39;Validity test failed&#39;</span><span class="p">),</span>

        <span class="c1"># The submission is waiting to be checked with the</span>
        <span class="c1"># full test script on one of the test machines.</span>
        <span class="c1"># The submission remains in this state until</span>
        <span class="c1"># some result was sent from the test machines.</span>
        <span class="p">(</span><span class="n">TEST_FULL_PENDING</span><span class="p">,</span> <span class="s1">&#39;Full test pending&#39;</span><span class="p">),</span>

        <span class="c1"># The (compilation and) validation of the student</span>
        <span class="c1"># sources on the test machine worked, only the full test</span>
        <span class="c1"># failed. No further automated action will take place with</span>
        <span class="c1"># this submission.</span>
        <span class="p">(</span><span class="n">TEST_FULL_FAILED</span><span class="p">,</span> <span class="s1">&#39;All but full test passed, grading pending&#39;</span><span class="p">),</span>

        <span class="c1"># The compilation (if configured) and the validation and</span>
        <span class="c1">#  the full test (if configured) of the submission were</span>
        <span class="c1"># successful. No further automated action will take</span>
        <span class="c1"># place with this submission.</span>
        <span class="p">(</span><span class="n">SUBMITTED_TESTED</span><span class="p">,</span> <span class="s1">&#39;All tests passed, grading pending&#39;</span><span class="p">),</span>

        <span class="c1"># Some grading took place in the teacher backend,</span>
        <span class="c1"># and the submission was explicitly marked with</span>
        <span class="c1"># &#39;grading not finished&#39;. This allows correctors to have</span>
        <span class="c1"># multiple runs over the submissions and see which</span>
        <span class="c1"># of the submissions were already investigated.</span>
        <span class="p">(</span><span class="n">GRADING_IN_PROGRESS</span><span class="p">,</span> <span class="s1">&#39;Grading not finished&#39;</span><span class="p">),</span>

        <span class="c1"># Some grading took place in the teacher backend,</span>
        <span class="c1"># and the submission was explicitly marked with</span>
        <span class="c1"># &#39;grading not finished&#39;. This allows correctors</span>
        <span class="c1"># to have multiple runs over the submissions and</span>
        <span class="c1">#  see which of the submissions were already investigated.</span>
        <span class="p">(</span><span class="n">GRADED</span><span class="p">,</span> <span class="s1">&#39;Grading finished&#39;</span><span class="p">),</span>

        <span class="c1"># The submission is closed, meaning that in the</span>
        <span class="c1"># teacher backend, the submission was marked</span>
        <span class="c1"># as closed to trigger the student notification</span>
        <span class="c1"># for their final assignment grades.</span>
        <span class="c1"># Students are notified by email.</span>
        <span class="p">(</span><span class="n">CLOSED</span><span class="p">,</span> <span class="s1">&#39;Closed, student notified&#39;</span><span class="p">),</span>

        <span class="c1"># The submission is closed, but marked for</span>
        <span class="c1"># another full test run.</span>
        <span class="c1"># This is typically used to have some post-assignment</span>
        <span class="c1"># analysis of student submissions</span>
        <span class="c1"># by the help of full test scripts.</span>
        <span class="c1"># Students never get any notification about this state.</span>
        <span class="p">(</span><span class="n">CLOSED_TEST_FULL_PENDING</span><span class="p">,</span> <span class="s1">&#39;Closed, full test pending&#39;</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># State description in student dashboard</span>
    <span class="n">STUDENT_STATES</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">RECEIVED</span><span class="p">,</span> <span class="s1">&#39;Received&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">WITHDRAWN</span><span class="p">,</span> <span class="s1">&#39;Withdrawn&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">SUBMITTED</span><span class="p">,</span> <span class="s1">&#39;Waiting for grading&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">TEST_VALIDITY_PENDING</span><span class="p">,</span> <span class="s1">&#39;Waiting for validation test&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">TEST_VALIDITY_FAILED</span><span class="p">,</span> <span class="s1">&#39;Validation failed&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">TEST_FULL_PENDING</span><span class="p">,</span> <span class="s1">&#39;Waiting for grading&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">TEST_FULL_FAILED</span><span class="p">,</span> <span class="s1">&#39;Waiting for grading&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">SUBMITTED_TESTED</span><span class="p">,</span> <span class="s1">&#39;Waiting for grading&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">GRADING_IN_PROGRESS</span><span class="p">,</span> <span class="s1">&#39;Waiting for grading&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">GRADED</span><span class="p">,</span> <span class="s1">&#39;Waiting for grading&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">CLOSED</span><span class="p">,</span> <span class="s1">&#39;Done&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">CLOSED_TEST_FULL_PENDING</span><span class="p">,</span> <span class="s1">&#39;Done&#39;</span><span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="section" id="submission-grading">
<h3>Submission grading<a class="headerlink" href="#submission-grading" title="Permalink to this headline">¶</a></h3>
<p>Location: <code class="docutils literal"><span class="pre">Teacher</span> <span class="pre">backend</span></code> - <code class="docutils literal"><span class="pre">Course</span></code> - <code class="docutils literal"><span class="pre">Manage</span> <span class="pre">submissions</span></code></p>
<p>Location: <code class="docutils literal"><span class="pre">Teacher</span> <span class="pre">backend</span></code> - <code class="docutils literal"><span class="pre">Course</span></code> - <code class="docutils literal"><span class="pre">Manage</span> <span class="pre">assignments</span></code>  - <code class="docutils literal"><span class="pre">Show</span> <span class="pre">submissions</span></code></p>
<p>The grading of student submissions always follows the same workflow, regardless of the fact if you are using the automated testing facilities or not.</p>
<p>Short version:</p>
<ul class="simple">
<li>For every submission:<ul>
<li>Open the submission in the teacher backend.</li>
<li>Use the preview function for inspecting uploaded student archives.</li>
<li>Check the output from validation test and full test.</li>
<li>Optional: Add grading notes and a grading file for the student as feedback.</li>
<li>Decide for a grading, based on the provided information.</li>
<li>Mark the submission as <strong>grading finished</strong> if you are done with it.</li>
</ul>
</li>
<li>Close and notify all finished submissions as bulk action.</li>
</ul>
<p>Long version:</p>
<p>On the right side of the submissions overview page, different filtering options are available.</p>
<img alt="_images/ui_backend_submissions.png" src="_images/ui_backend_submissions.png" />
<p>The most important thing is the distinguishing between <strong>non-graded</strong>, <strong>graded</strong> and <strong>closed</strong> submissions:</p>
<p><strong>Non-graded</strong> submissions are the ones that were submitted (and successfully validated) before the hard deadline. Your task is to go through these submissions and decided for a particular grading. If this is done, than the grading is marked as being completed for this particular submission. This moves it into the <strong>graded</strong> state.</p>
<p>When all gradings are done, then the submissions can be <strong>closed</strong>. This is the point in time were the status for the students changes, before that, no notification is done. The idea here is to first finish the grading - maybe with multiple people being involved - before notifying all students about their results. Only submissions in the <strong>graded</strong> status can be closed. This is a safeguard to not forget the finishing of some grading procedure.</p>
<p>The submission details dialogue shows different information:</p>
<img alt="_images/ui_backend_submission.png" src="_images/ui_backend_submission.png" />
<p>The assignment may allow the students to define co-authors for their submission. You can edit this list manually, for example when students made a mistake during the submission. The according section is hidden by default, click on the <cite>Authors</cite> tab to see it.</p>
<p>The original <em>submitter</em> of the solution is stated separately. Submitters automatically become authors.</p>
<p>Students can always add notes to their submission. If file upload is disabled for the assignment, this is the only gradable information.</p>
<p>The <em>file upload</em> of the students is available for direct download, simply by clicking on the file name. This is especially relevant when having text or PDF document as solution attachment. The <em>Preview</em> link opens a separate web page with a preview of the file resp. the archive content.</p>
<p>When <a class="reference internal" href="#testing"><span class="std std-ref">testing</span></a> is activated for this assignment, then the according result output is shown in the submission details.</p>
<p>The choice of a <em>grading</em> is offered according to the <a class="reference internal" href="#gradingscheme"><span class="std std-ref">grading scheme</span></a> being configured for the particular assignment. The <em>grading notes</em> are shown in the student frontend, together with the grade, when the submission is closed.</p>
<p>The <em>grading file</em> is also offered after closing, and may - for example - contain some explanary template solution or a manually annotated version of the student file upload.</p>
<p>The radio buttons at the bottom of the page allow to mark the submission as <strong>non-graded</strong> or <strong>graded</strong>.</p>
<p>When all submissions are finally graded, it is time to release the information to the students. In order to do this, mark on the overview page all finished submissions. This can be easily done by using the filters on the right side and the ‘mark all’ checkbox in the upper left corner. The choose the action ‘Close graded submissions + send notification’.</p>
</div>
<div class="section" id="grading-table">
<span id="gradingtable"></span><h3>Grading table<a class="headerlink" href="#grading-table" title="Permalink to this headline">¶</a></h3>
<p>Location: <code class="docutils literal"><span class="pre">Teacher</span> <span class="pre">backend</span></code> - <code class="docutils literal"><span class="pre">Course</span></code> - <code class="docutils literal"><span class="pre">Show</span> <span class="pre">grading</span> <span class="pre">table</span></code></p>
<p>If you want to have a course-level overview of all student results so far, use the <em>grading table</em> overview. It is available as action in the <em>Courses</em> section of the teacher backend.</p>
</div>
<div class="section" id="duplicate-report">
<h3>Duplicate report<a class="headerlink" href="#duplicate-report" title="Permalink to this headline">¶</a></h3>
<p>Location: <code class="docutils literal"><span class="pre">Teacher</span> <span class="pre">backend</span></code> - <code class="docutils literal"><span class="pre">Course</span></code> - <code class="docutils literal"><span class="pre">Manage</span> <span class="pre">assignments</span></code>  - <code class="docutils literal"><span class="pre">Show</span> <span class="pre">duplicates</span></code></p>
<p>A common task in assignment correction is the detection of cheating. In OpenSubmit terms, this leads to the question if different students have submitted identical, or at least very similar, solutions for an assignment.</p>
<p>Checking arbitrary code for similarities is a complex topic by itself and is closely related to the type and amount of code being checked. OpenSubmit follows it general <a class="reference internal" href="about.html#principles"><span class="std std-ref">principles</span></a> here by not restricting the possible types of submission for a perfect duplicate detection. Instead, we encourage users with specific demands to use such services in their <a class="reference internal" href="#testing"><span class="std std-ref">testing scripts</span></a>.</p>
<p>OpenSubmit provides a basic duplicate checking for submitted files based on weak hashing of the student archives content. This method works independently from the kind of data and can, at least, detect the most lazy attempts of re-using other peoples work.</p>
<p>Based on the hashing results, the duplicate report shows groups of students that may have submitted the same result. This list must be treated as basic indication for further manual inspection. The report works independently from the course and the status of the submissions. Withdrawn solutions are skipped in the report.</p>
</div>
</div>
<div class="section" id="automated-testing-of-submissions">
<span id="testing"></span><h2>Automated testing of submissions<a class="headerlink" href="#automated-testing-of-submissions" title="Permalink to this headline">¶</a></h2>
<p>The automated testing of submissions is performed by a Python 3 script that you, the assignment creator, have to write. This script is executed by OpenSubmit on some configured <a class="reference internal" href="admin_use.html#executors"><span class="std std-ref">test machines</span></a>. You are completely free in what you want to do in this script - at the end, OpenSubmit just needs an indication about the result. Common tasks, such as code compilation and execution, are supported by helper functions you can use in this script.</p>
<p>You can upload such a script in two ways:</p>
<ul class="simple">
<li>As single Python file named <cite>validator.py</cite>.</li>
<li>As ZIP / TGZ archive with an arbitrary name, which must contain a file named <cite>validator.py</cite>.</li>
</ul>
<p>The second option allows you to deploy additional files (e.g. profiling tools, libraries, code not written by students) to the test machine. OpenSubmit ensures that all these files are stored in the same directory as the student code and the Python script.</p>
<div class="section" id="how-to-write-a-test-script">
<h3>How to write a test script<a class="headerlink" href="#how-to-write-a-test-script" title="Permalink to this headline">¶</a></h3>
<p>Test scripts are written in Python 3.4 and will be directly called by the OpenSubmit daemon running on test machines.</p>
<p>You can install this daemon, which is also called <em>executor</em>, on your own computer easily. This gives you an offline development environment for test scripts while you are working on the assignment description.</p>
<p>Similar to the installation of <a class="reference internal" href="admin_use.html#executors"><span class="std std-ref">test machines</span></a>, the following procedure (for Debian / Ubuntu systems) gives you a testing environment:</p>
<ul class="simple">
<li>Install Python 3: <code class="docutils literal"><span class="pre">sudo</span> <span class="pre">apt-get</span> <span class="pre">install</span> <span class="pre">python3</span> <span class="pre">python3-pip</span></code></li>
</ul>
<p>To keep your Python installation clean, we recommend to use <a class="reference external" href="https://virtualenv.pypa.io/en/stable/">Virtualenv</a>:</p>
<ul class="simple">
<li>Install the Virtualenv tool: <code class="docutils literal"><span class="pre">sudo</span> <span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">virtualenv</span></code></li>
<li>Create a new virtual environment, e.g. in <code class="docutils literal"><span class="pre">~/my_env</span></code>: <code class="docutils literal"><span class="pre">python3</span> <span class="pre">-m</span> <span class="pre">virtualenv</span> <span class="pre">~/my_env</span></code></li>
<li>Activate it with <code class="docutils literal"><span class="pre">source</span> <span class="pre">~/my_env/bin/activate</span></code></li>
<li>Install the OpenSubmit validator library / executor inside: <code class="docutils literal"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">opensubmit-exec</span></code></li>
<li>Develop the <cite>validator.py</cite> for your assignment.</li>
</ul>
<p>Examples for test scripts can be found <a class="reference external" href="https://github.com/troeger/opensubmit/tree/master/examples">online</a>.</p>
<p>We illustrate the idea with the following walk-through example:</p>
<p>Students get the assignment to create a C program that prints ‘Hello World’ on the terminal. The assignment description demands that they submit the C-file and a <em>Makefile</em> that creates a program called <em>hello</em>. The assignment description also explains that the students have to <a class="reference external" href="_newsubmission">submit a ZIP archive</a> containing both files.</p>
<p>Your job, as the assignment creator, is now to develop the <code class="docutils literal"><span class="pre">validator.py</span></code> file that checks an arbitrary student submission. Create a fresh directory that only contains an example student upload and the validator file:</p>
<div class="highlight-default"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">job</span><span class="p">):</span>
    <span class="n">job</span><span class="o">.</span><span class="n">run_make</span><span class="p">(</span><span class="n">mandatory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">exit_code</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">run_program</span><span class="p">(</span><span class="s1">&#39;./hello&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">output</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;hello world&quot;</span><span class="p">:</span>
        <span class="n">job</span><span class="o">.</span><span class="n">send_pass_result</span><span class="p">(</span><span class="s2">&quot;The world greets you! Everything worked fine!&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">job</span><span class="o">.</span><span class="n">send_fail_result</span><span class="p">(</span><span class="s2">&quot;Wrong output: &quot;</span> <span class="o">+</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<p>The <code class="docutils literal"><span class="pre">validator.py</span></code> file must contain a function <code class="docutils literal"><span class="pre">validate(job)</span></code> that is called by OpenSubmit when a student submission should be validated. In the example above, this function performs the following steps for testing:</p>
<ul class="simple">
<li>Line 1: The validator function is called when all student files (and all files from the validator archive) are unpacked in a temporary working directory on the test machine. In case of name conflicts, the validator files always overwrite the student files.</li>
<li>Line 2: The <em>make</em> tool is executed in the working directory with <code class="xref py py-meth docutils literal"><span class="pre">run_make()</span></code>. This step is declared to be mandatory, so the method will throw an exception if <em>make</em> fails.</li>
<li>Line 3: A binary called <em>hello</em> is executed in the working directory with the helper function <a class="reference internal" href="#opensubmitexec.job.Job.run_program" title="opensubmitexec.job.Job.run_program"><code class="xref py py-meth docutils literal"><span class="pre">run_program()</span></code></a>. The result is the exit code and the output of the running program.</li>
<li>Line 4: The generated output of the student program is checked for some expected text.</li>
<li>Line 5: A positive validation result is sent back to the OpenSubmit web application with <a class="reference internal" href="#opensubmitexec.job.Job.send_pass_result" title="opensubmitexec.job.Job.send_pass_result"><code class="xref py py-meth docutils literal"><span class="pre">send_pass_result()</span></code></a>. The text is shown to students in their dashboard.</li>
<li>Line 6: A negative validation result is sent back to the OpenSubmit web application with <a class="reference internal" href="#opensubmitexec.job.Job.send_fail_result" title="opensubmitexec.job.Job.send_fail_result"><code class="xref py py-meth docutils literal"><span class="pre">send_fail_result()</span></code></a>. The text is shown to students in their dashboard.</li>
</ul>
<p>Test scripts are ordinary Python code, so beside the functionalities provided by the job object, you can use any Python functionality. The example shows that in Line 4.</p>
<p>If any part of the code leads to an exception that is not catched inside <code class="docutils literal"><span class="pre">validate(job)</span></code>, than this is automatically interpreted as negative validation result. The OpenSubmit executor code forwards the exception as generic information to the student. If you want to customize the error reporting, catch all potential exceptions and use your own call of <a class="reference internal" href="#opensubmitexec.job.Job.send_fail_result" title="opensubmitexec.job.Job.send_fail_result"><code class="xref py py-meth docutils literal"><span class="pre">send_fail_result()</span></code></a> instead.</p>
<p>To check if the validator is working correctly, you can run the command <code class="docutils literal"><span class="pre">opensubmit-exec</span> <span class="pre">test</span> <span class="pre">&lt;directory&gt;</span></code> in your VirtualEnv. It assumes the given directory to contain a validator script resp. archive and the student submission file resp. archive. The command simulates a complete validation run on a test machine and prints exhaustive debugging information. The last line contains the feedback sent to the web application after finalization.</p>
</div>
<div class="section" id="test-script-examples">
<h3>Test script examples<a class="headerlink" href="#test-script-examples" title="Permalink to this headline">¶</a></h3>
<p>The following example shows a validator for a program in C that prints the sum of two integer values. The values are given as command line arguments. If the wrong number of arguments is given, the student code is expected to print <cite>“Wrong number of arguments!”</cite>. The student only has to submit the C file.</p>
<div class="highlight-default"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">opensubmitexec.compiler</span> <span class="k">import</span> <span class="n">GCC</span>

<span class="n">test_cases</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;2&#39;</span><span class="p">],</span> <span class="s1">&#39;3&#39;</span><span class="p">],</span>
    <span class="p">[[</span><span class="s1">&#39;-1&#39;</span><span class="p">,</span> <span class="s1">&#39;-2&#39;</span><span class="p">],</span> <span class="s1">&#39;-3&#39;</span><span class="p">],</span>
    <span class="p">[[</span><span class="s1">&#39;-2&#39;</span><span class="p">,</span> <span class="s1">&#39;2&#39;</span><span class="p">],</span> <span class="s1">&#39;0&#39;</span><span class="p">],</span>
    <span class="p">[[</span><span class="s1">&#39;4&#39;</span><span class="p">,</span> <span class="s1">&#39;-10&#39;</span><span class="p">],</span> <span class="s1">&#39;-6&#39;</span><span class="p">],</span>
    <span class="p">[[</span><span class="s1">&#39;4&#39;</span><span class="p">],</span> <span class="s1">&#39;Wrong number of arguments!&#39;</span><span class="p">],</span>
    <span class="p">[[</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">],</span> <span class="s1">&#39;Wrong number of arguments!&#39;</span><span class="p">]</span>
<span class="p">]</span>

<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">job</span><span class="p">):</span>
    <span class="n">job</span><span class="o">.</span><span class="n">run_compiler</span><span class="p">(</span><span class="n">compiler</span><span class="o">=</span><span class="n">GCC</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sum.c&#39;</span><span class="p">],</span> <span class="n">output</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">arguments</span><span class="p">,</span> <span class="n">expected_output</span> <span class="ow">in</span> <span class="n">test_cases</span><span class="p">:</span>
        <span class="n">exit_code</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">run_program</span><span class="p">(</span><span class="s1">&#39;./sum&#39;</span><span class="p">,</span> <span class="n">arguments</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">output</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">!=</span> <span class="n">expected_output</span><span class="p">:</span>
            <span class="n">job</span><span class="o">.</span><span class="n">send_fail_result</span><span class="p">(</span><span class="s2">&quot;Oops! That went wrong! Input: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">arguments</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;, Output: &quot;</span> <span class="o">+</span> <span class="n">output</span><span class="p">,</span> <span class="s2">&quot;Student needs support.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
    <span class="n">job</span><span class="o">.</span><span class="n">send_pass_result</span><span class="p">(</span><span class="s2">&quot;Good job! Your program worked as expected!&quot;</span><span class="p">,</span> <span class="s2">&quot;Student seems to be capable.&quot;</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<ul class="simple">
<li>Line 1: The <cite>GCC</cite> tuple constant is predefined by the OpenSubmit library and refers to the well-known GNU C compiler. You can also define your own set of command-line arguments for another compiler.</li>
<li>Line 3-10: The variable <cite>test_cases</cite> consists of the lists of inputs and the corresponding expected outputs.</li>
<li>Line 13: The C file can be compiled directly by using <a class="reference internal" href="#opensubmitexec.job.Job.run_compiler" title="opensubmitexec.job.Job.run_compiler"><code class="xref py py-meth docutils literal"><span class="pre">run_compiler()</span></code></a>. You can specify the used compiler as well as the names of the input and output files.</li>
<li>Line 14: The for-loop is used for traversing the <cite>test_cases</cite>-list. It consists of tuples which are composed of the arguments and the expected output.</li>
<li>Line 15: The arguments can be handed over to the program through the second parameter of the <a class="reference internal" href="#opensubmitexec.job.Job.run_program" title="opensubmitexec.job.Job.run_program"><code class="xref py py-meth docutils literal"><span class="pre">run_program()</span></code></a> method. The former method returns the exit code as well as the output of the program.</li>
<li>Line 16: It is checked if the created output equals the expected output.</li>
<li>Line 17: If this is not the case an appropriate negative result is sent to the student and teacher with <a class="reference internal" href="#opensubmitexec.job.Job.send_fail_result" title="opensubmitexec.job.Job.send_fail_result"><code class="xref py py-meth docutils literal"><span class="pre">send_fail_result()</span></code></a></li>
<li>Line 18: After a negative result is sent there is no need for traversing the rest of the test cases, so the <cite>validate(job)</cite> function can be left.</li>
<li>Line 19: After the traversal of all test cases, the student and teacher are informed that everything went well with <a class="reference internal" href="#opensubmitexec.job.Job.send_pass_result" title="opensubmitexec.job.Job.send_pass_result"><code class="xref py py-meth docutils literal"><span class="pre">send_pass_result()</span></code></a></li>
</ul>
<p>The following example shows a validator for a C program that reads an positive integer from standard input und prints the corresponding binary number.</p>
<div class="highlight-default"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">opensubmitexec.exceptions</span> <span class="k">import</span> <span class="n">TerminationException</span>

<span class="n">test_cases</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s1">&#39;0&#39;</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">],</span>
    <span class="p">[</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">],</span>
    <span class="p">[</span><span class="s1">&#39;8&#39;</span><span class="p">,</span> <span class="s1">&#39;1000&#39;</span><span class="p">],</span>
    <span class="p">[</span><span class="s1">&#39;9&#39;</span><span class="p">,</span> <span class="s1">&#39;1001&#39;</span><span class="p">],</span>
    <span class="p">[</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="s1">&#39;1111&#39;</span><span class="p">]</span>
<span class="p">]</span>

<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">job</span><span class="p">):</span>
    <span class="n">job</span><span class="o">.</span><span class="n">run_build</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;dec_to_bin.c&#39;</span><span class="p">],</span> <span class="n">output</span><span class="o">=</span><span class="s1">&#39;dec_to_bin&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">std_input</span><span class="p">,</span> <span class="n">expected_output</span> <span class="ow">in</span> <span class="n">test_cases</span><span class="p">:</span>
        <span class="n">running</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">spawn_program</span><span class="p">(</span><span class="s1">&#39;./dec_to_bin&#39;</span><span class="p">)</span>
        <span class="n">running</span><span class="o">.</span><span class="n">sendline</span><span class="p">(</span><span class="n">std_input</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">running</span><span class="o">.</span><span class="n">expect</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">TerminationException</span><span class="p">:</span>
            <span class="n">job</span><span class="o">.</span><span class="n">send_fail_result</span><span class="p">(</span><span class="s2">&quot;Arrgh, a problem: We expected </span><span class="si">{0}</span><span class="s2"> as output for the input </span><span class="si">{1}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">std_input</span><span class="p">),</span> <span class="s2">&quot;wrong output&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">running</span><span class="o">.</span><span class="n">expect_end</span><span class="p">()</span>
    <span class="n">job</span><span class="o">.</span><span class="n">send_pass_result</span><span class="p">(</span><span class="s2">&quot;Everything worked fine!&quot;</span><span class="p">,</span> <span class="s2">&quot;Student seems to be capable.&quot;</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<ul class="simple">
<li>Line 1: A <cite>TimeoutException</cite> is thrown when a program does not respond in the given time. The exception is needed for checking if the student program calculates fast enough.</li>
<li>Line 3-9: In this case the test cases consist of the input strings and the corresponding output strings.</li>
<li>Line 12: The method <a class="reference internal" href="#opensubmitexec.job.Job.run_build" title="opensubmitexec.job.Job.run_build"><code class="xref py py-meth docutils literal"><span class="pre">run_build()</span></code></a> is a combined call of <cite>configure</cite>, <cite>make</cite> and the compiler. The success of <cite>make</cite> and <cite>configure</cite> is optional. The default value for the compiler is GCC.</li>
<li>Line 13: The test cases are traversed like in the previous example.</li>
<li>Line 14: This time a program is spawned with <a class="reference internal" href="#opensubmitexec.job.Job.spawn_program" title="opensubmitexec.job.Job.spawn_program"><code class="xref py py-meth docutils literal"><span class="pre">spawn_program()</span></code></a>. This allows the interaction with the running program.</li>
<li>Line 15: Standard input resp. keyboard input can be provided through the <a class="reference internal" href="#opensubmitexec.running.RunningProgram.sendline" title="opensubmitexec.running.RunningProgram.sendline"><code class="xref py py-meth docutils literal"><span class="pre">sendline()</span></code></a> method of the returned object from line 14.</li>
<li>Line 17-20: The validator waits for the expected output with <a class="reference internal" href="#opensubmitexec.running.RunningProgram.expect" title="opensubmitexec.running.RunningProgram.expect"><code class="xref py py-meth docutils literal"><span class="pre">expect()</span></code></a>. If the program terminates without producing this output, a <cite>TerminationException</cite> exception is thrown.</li>
<li>Line 22: After the program successfully produced the output, it is expected to terminate. The test script waits for this with <a class="reference internal" href="#opensubmitexec.running.RunningProgram.expect_end" title="opensubmitexec.running.RunningProgram.expect_end"><code class="xref py py-meth docutils literal"><span class="pre">expect_end()</span></code></a></li>
<li>Line 23: When the loop finishes, a positive result is sent to the student and teacher with <a class="reference internal" href="#opensubmitexec.job.Job.send_pass_result" title="opensubmitexec.job.Job.send_pass_result"><code class="xref py py-meth docutils literal"><span class="pre">send_pass_result()</span></code></a>.</li>
</ul>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">When using <a class="reference internal" href="#opensubmitexec.running.RunningProgram.expect" title="opensubmitexec.running.RunningProgram.expect"><code class="xref py py-meth docutils literal"><span class="pre">expect()</span></code></a>, it is important to explicitely catch a  <cite>TerminationException</cite> and make an explicit fail report in your validation script. Otherwise, the student is only informed about an unexpected termination without further explanation.</p>
</div>
<p>The following example shows a validator for a C program that reads a string from standard input and prints it reversed. The students have to use for-loops for solving the task. Only the C file has to be submitted.</p>
<div class="highlight-default"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">opensubmitexec.exceptions</span> <span class="k">import</span> <span class="n">TimeoutException</span>
<span class="kn">from</span> <span class="nn">opensubmitexec.exceptions</span> <span class="k">import</span> <span class="n">TerminationException</span>

<span class="n">test_cases</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s1">&#39;hallo&#39;</span><span class="p">,</span> <span class="s1">&#39;ollah&#39;</span><span class="p">],</span>
    <span class="p">[</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">],</span>
    <span class="p">[</span><span class="s1">&#39;1234&#39;</span><span class="p">,</span> <span class="s1">&#39;4321&#39;</span><span class="p">]</span>
<span class="p">]</span>

<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">job</span><span class="p">):</span>
    <span class="n">file_names</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">grep</span><span class="p">(</span><span class="s1">&#39;.*for[:space:]*(.*;.*;.*).*&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">file_names</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">job</span><span class="o">.</span><span class="n">send_fail_result</span><span class="p">(</span><span class="s2">&quot;You probably did not use a for-loop.&quot;</span><span class="p">,</span> <span class="s2">&quot;Student is not able to use a for-loop.&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="n">job</span><span class="o">.</span><span class="n">run_build</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;reverse.c&#39;</span><span class="p">],</span> <span class="n">output</span><span class="o">=</span><span class="s1">&#39;reverse&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">std_input</span><span class="p">,</span> <span class="n">expected_output</span> <span class="ow">in</span> <span class="n">test_cases</span><span class="p">:</span>
        <span class="n">running</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">spawn_program</span><span class="p">(</span><span class="s1">&#39;./reverse&#39;</span><span class="p">)</span>
        <span class="n">running</span><span class="o">.</span><span class="n">sendline</span><span class="p">(</span><span class="n">std_input</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">running</span><span class="o">.</span><span class="n">expect</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">TimeoutException</span><span class="p">:</span>
            <span class="n">job</span><span class="o">.</span><span class="n">send_fail_result</span><span class="p">(</span><span class="s2">&quot;Your output took to long!&quot;</span><span class="p">,</span> <span class="s2">&quot;timeout&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="k">except</span> <span class="n">TerminationException</span><span class="p">:</span>
            <span class="n">job</span><span class="o">.</span><span class="n">send_fail_result</span><span class="p">(</span><span class="s2">&quot;The string was not reversed correctly for the following input: &quot;</span> <span class="o">+</span> <span class="n">std_input</span><span class="p">,</span> <span class="s2">&quot;The student does not seem to be capable.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">running</span><span class="o">.</span><span class="n">expect_end</span><span class="p">()</span>
    <span class="n">job</span><span class="o">.</span><span class="n">send_pass_result</span><span class="p">(</span><span class="s2">&quot;Everything worked fine!&quot;</span><span class="p">,</span> <span class="s2">&quot;Student seems to be capable.&quot;</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<ul class="simple">
<li>Line 1: A <cite>TimeoutException</cite> is thrown when a program does not respond in the given time. The exception is needed for checking if the student program calculates fast enough.</li>
<li>Line 2: A <cite>TerminationException</cite> is thrown when a program terminates before delivering the expected output.</li>
<li>Line 4-8: The test cases consist of the input strings and the corresponding reversed output strings.</li>
<li>Line 11: The <a class="reference internal" href="#opensubmitexec.job.Job.grep" title="opensubmitexec.job.Job.grep"><code class="xref py py-meth docutils literal"><span class="pre">grep()</span></code></a> method searches the student files for the given pattern (e.g. a for-loop) and returns a list of the files containing it.</li>
<li>Line 12-14: If there are not enough elements in the list, a negative result is sent with <a class="reference internal" href="#opensubmitexec.job.Job.send_fail_result" title="opensubmitexec.job.Job.send_fail_result"><code class="xref py py-meth docutils literal"><span class="pre">send_fail_result()</span></code></a> and the validation is ended.</li>
<li>Line 16-24: For every test case a new program is spawned with <a class="reference internal" href="#opensubmitexec.job.Job.spawn_program" title="opensubmitexec.job.Job.spawn_program"><code class="xref py py-meth docutils literal"><span class="pre">spawn_program()</span></code></a>. The test script provides the neccessary input with <a class="reference internal" href="#opensubmitexec.running.RunningProgram.sendline" title="opensubmitexec.running.RunningProgram.sendline"><code class="xref py py-meth docutils literal"><span class="pre">sendline()</span></code></a> and waits for the expected output with <a class="reference internal" href="#opensubmitexec.running.RunningProgram.expect" title="opensubmitexec.running.RunningProgram.expect"><code class="xref py py-meth docutils literal"><span class="pre">expect()</span></code></a>. If the program is calculating for too long, a negative result is sent with <a class="reference internal" href="#opensubmitexec.job.Job.send_fail_result" title="opensubmitexec.job.Job.send_fail_result"><code class="xref py py-meth docutils literal"><span class="pre">send_fail_result()</span></code></a>.</li>
<li>Line 25: If the result is different from the expected output a <cite>TerminationException</cite> is raised.</li>
<li>Line 26-27: The corresponding negative result for a different output is sent with <a class="reference internal" href="#opensubmitexec.job.Job.send_fail_result" title="opensubmitexec.job.Job.send_fail_result"><code class="xref py py-meth docutils literal"><span class="pre">send_fail_result()</span></code></a> and the validation is cancelled.</li>
<li>Line 28-29: If the program produced the expected output the validator waits  with <a class="reference internal" href="#opensubmitexec.running.RunningProgram.expect_end" title="opensubmitexec.running.RunningProgram.expect_end"><code class="xref py py-meth docutils literal"><span class="pre">expect_end()</span></code></a> until the spawned program ends.</li>
<li>Line 30: If every test case was solved correctly, a positive result is sent with <a class="reference internal" href="#opensubmitexec.job.Job.send_pass_result" title="opensubmitexec.job.Job.send_pass_result"><code class="xref py py-meth docutils literal"><span class="pre">send_pass_result()</span></code></a>.</li>
</ul>
</div>
</div>
<div class="section" id="developer-reference">
<h2>Developer reference<a class="headerlink" href="#developer-reference" title="Permalink to this headline">¶</a></h2>
<p>The Job class summarizes all information about the submission to be validated by the test script. It also offers a set of helper functions that can be directly used by the test script implementation.</p>
<dl class="class">
<dt id="opensubmitexec.job.Job">
<em class="property">class </em><code class="descclassname">opensubmitexec.job.</code><code class="descname">Job</code><span class="sig-paren">(</span><em>config=None</em>, <em>online=True</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job" title="Permalink to this definition">¶</a></dt>
<dd><p>A OpenSubmit validation job to be done.</p>
<dl class="attribute">
<dt id="opensubmitexec.job.Job.working_dir">
<code class="descname">working_dir</code><a class="headerlink" href="#opensubmitexec.job.Job.working_dir" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – The working directory with all student and test script files.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.job.Job.timeout">
<code class="descname">timeout</code><a class="headerlink" href="#opensubmitexec.job.Job.timeout" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – The timeout for execution, as configured in the assignment settings.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.job.Job.submission_id">
<code class="descname">submission_id</code><a class="headerlink" href="#opensubmitexec.job.Job.submission_id" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – The OpenSubmit submission ID.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.job.Job.file_id">
<code class="descname">file_id</code><a class="headerlink" href="#opensubmitexec.job.Job.file_id" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – The OpenSubmit submission file ID.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.job.Job.submitter_name">
<code class="descname">submitter_name</code><a class="headerlink" href="#opensubmitexec.job.Job.submitter_name" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – Real name of the submitting student.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.job.Job.submitter_student_id">
<code class="descname">submitter_student_id</code><a class="headerlink" href="#opensubmitexec.job.Job.submitter_student_id" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – Student ID of the submitting student.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.job.Job.submitter_studyprogram">
<code class="descname">submitter_studyprogram</code><a class="headerlink" href="#opensubmitexec.job.Job.submitter_studyprogram" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – Study program of the submitting student.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.job.Job.author_names">
<code class="descname">author_names</code><a class="headerlink" href="#opensubmitexec.job.Job.author_names" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – Real names of all authors.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.job.Job.course">
<code class="descname">course</code><a class="headerlink" href="#opensubmitexec.job.Job.course" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – Name of the course for this submission.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.job.Job.assignment">
<code class="descname">assignment</code><a class="headerlink" href="#opensubmitexec.job.Job.assignment" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – Name of the assignment for this submission.</p>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.delete_binaries">
<code class="descname">delete_binaries</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.delete_binaries" title="Permalink to this definition">¶</a></dt>
<dd><p>Scans for binary files in the student submission and deletes them.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The list of deleted files.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.ensure_files">
<code class="descname">ensure_files</code><span class="sig-paren">(</span><em>filenames</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.ensure_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks the student submission for specific files.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>filenames</strong> (<em>tuple</em>) – The list of file names to be cjecked for.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Indicator if all files are found in the student archive.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">bool</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.grep">
<code class="descname">grep</code><span class="sig-paren">(</span><em>regex</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.grep" title="Permalink to this definition">¶</a></dt>
<dd><p>Scans the student files for text patterns.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>regex</strong> (<em>str</em>) – Regular expression used for scanning inside the files.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Names of the matching files in the working directory.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tuple</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.run_build">
<code class="descname">run_build</code><span class="sig-paren">(</span><em>compiler=['gcc', '-o', '{output}', '{inputs}'], inputs=None, output=None</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.run_build" title="Permalink to this definition">¶</a></dt>
<dd><p>Combined call of ‘configure’, ‘make’ and the compiler.</p>
<p>The success of ‘configure’ and ‘make’ is optional.
The arguments are the same as for run_compiler.</p>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.run_compiler">
<code class="descname">run_compiler</code><span class="sig-paren">(</span><em>compiler=['gcc', '-o', '{output}', '{inputs}'], inputs=None, output=None</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.run_compiler" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs a compiler in the working directory.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>compiler</strong> (<em>tuple</em>) – The compiler program and its command-line arguments,
including placeholders for output and input files.</li>
<li><strong>inputs</strong> (<em>tuple</em>) – The list of input files for the compiler.</li>
<li><strong>output</strong> (<em>str</em>) – The name of the output file.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.run_configure">
<code class="descname">run_configure</code><span class="sig-paren">(</span><em>mandatory=True</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.run_configure" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the ‘configure’ program in the working directory.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>mandatory</strong> (<em>bool</em>) – Throw exception if ‘configure’ fails or a
‘configure’ file is missing.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.run_make">
<code class="descname">run_make</code><span class="sig-paren">(</span><em>mandatory=True</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.run_make" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the ‘make’ program in the working directory.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>mandatory</strong> (<em>bool</em>) – Throw exception if ‘make’ fails or a
‘Makefile’ file is missing.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.run_program">
<code class="descname">run_program</code><span class="sig-paren">(</span><em>name</em>, <em>arguments=[]</em>, <em>timeout=30</em>, <em>exclusive=False</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.run_program" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs a program in the working directory to completion.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>name</strong> (<em>str</em>) – The name of the program to be executed.</li>
<li><strong>arguments</strong> (<em>tuple</em>) – Command-line arguments for the program.</li>
<li><strong>timeout</strong> (<em>int</em>) – The timeout for execution.</li>
<li><strong>exclusive</strong> (<em>bool</em>) – Prevent parallel validation runs on the
test machines, e.g. when doing performance
measurements for submitted code.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tuple of the exit code, as reported by the operating system,
and the output produced during the execution.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tuple</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.send_fail_result">
<code class="descname">send_fail_result</code><span class="sig-paren">(</span><em>info_student</em>, <em>info_tutor='Test failed.'</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.send_fail_result" title="Permalink to this definition">¶</a></dt>
<dd><p>Reports a negative result for this validation job.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>info_student</strong> (<em>str</em>) – Information for the student(s)</li>
<li><strong>info_tutor</strong> (<em>str</em>) – Information for the tutor(s)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.send_pass_result">
<code class="descname">send_pass_result</code><span class="sig-paren">(</span><em>info_student='All tests passed. Awesome!'</em>, <em>info_tutor='All tests passed.'</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.send_pass_result" title="Permalink to this definition">¶</a></dt>
<dd><p>Reports a positive result for this validation job.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>info_student</strong> (<em>str</em>) – Information for the student(s)</li>
<li><strong>info_tutor</strong> (<em>str</em>) – Information for the tutor(s)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.job.Job.spawn_program">
<code class="descname">spawn_program</code><span class="sig-paren">(</span><em>name</em>, <em>arguments=[]</em>, <em>timeout=30</em>, <em>exclusive=False</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.job.Job.spawn_program" title="Permalink to this definition">¶</a></dt>
<dd><p>Spawns a program in the working directory.</p>
<p>This method allows the interaction with the running program,
based on the returned RunningProgram object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>name</strong> (<em>str</em>) – The name of the program to be executed.</li>
<li><strong>arguments</strong> (<em>tuple</em>) – Command-line arguments for the program.</li>
<li><strong>timeout</strong> (<em>int</em>) – The timeout for execution.</li>
<li><strong>exclusive</strong> (<em>bool</em>) – Prevent parallel validation runs on the
test machines, e.g. when doing performance
measurements for submitted code.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">An object representing the running program.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#opensubmitexec.running.RunningProgram" title="opensubmitexec.running.RunningProgram">RunningProgram</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<p>Test scripts can interact with a running student program, to send some simulated keyboard input and check the resulting output for expected text patterns.</p>
<dl class="class">
<dt id="opensubmitexec.running.RunningProgram">
<em class="property">class </em><code class="descclassname">opensubmitexec.running.</code><code class="descname">RunningProgram</code><span class="sig-paren">(</span><em>job</em>, <em>name</em>, <em>arguments=[]</em>, <em>timeout=30</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.running.RunningProgram" title="Permalink to this definition">¶</a></dt>
<dd><p>A running program that you can interact with.</p>
<p>This class is a thin wrapper around the functionality
of pexpect (<a class="reference external" href="http://pexpect.readthedocs.io/en/stable/overview.html">http://pexpect.readthedocs.io/en/stable/overview.html</a>).</p>
<dl class="attribute">
<dt id="opensubmitexec.running.RunningProgram.job">
<code class="descname">job</code><a class="headerlink" href="#opensubmitexec.running.RunningProgram.job" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Job</em> – The original job for this program execution.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.running.RunningProgram.name">
<code class="descname">name</code><a class="headerlink" href="#opensubmitexec.running.RunningProgram.name" title="Permalink to this definition">¶</a></dt>
<dd><p><em>str</em> – The name of the binary that is executed.</p>
</dd></dl>

<dl class="attribute">
<dt id="opensubmitexec.running.RunningProgram.arguments">
<code class="descname">arguments</code><a class="headerlink" href="#opensubmitexec.running.RunningProgram.arguments" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tuple</em> – The command-line arguments being used for execution.</p>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.running.RunningProgram.expect">
<code class="descname">expect</code><span class="sig-paren">(</span><em>pattern</em>, <em>timeout=-1</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.running.RunningProgram.expect" title="Permalink to this definition">¶</a></dt>
<dd><p>Deprecated. Use expect_output() instead.</p>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.running.RunningProgram.expect_end">
<code class="descname">expect_end</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.running.RunningProgram.expect_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Wait for the running program to finish.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A tuple with the exit code, as reported by the operating system, and the output produced.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.running.RunningProgram.expect_exit_status">
<code class="descname">expect_exit_status</code><span class="sig-paren">(</span><em>exit_status</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.running.RunningProgram.expect_exit_status" title="Permalink to this definition">¶</a></dt>
<dd><p>Deprecated. Use expect_exitstatus() instead.</p>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.running.RunningProgram.expect_exitstatus">
<code class="descname">expect_exitstatus</code><span class="sig-paren">(</span><em>exit_status</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.running.RunningProgram.expect_exitstatus" title="Permalink to this definition">¶</a></dt>
<dd><p>Wait for the running program to finish and expect some exit status.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>exit_status</strong> (<em>int</em>) – The expected exit status.</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><code class="xref py py-exc docutils literal"><span class="pre">WrongExitStatusException</span></code> – The produced exit status is not the expected one.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.running.RunningProgram.expect_output">
<code class="descname">expect_output</code><span class="sig-paren">(</span><em>pattern</em>, <em>timeout=-1</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.running.RunningProgram.expect_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Wait until the running program performs some given output, or terminates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>pattern</strong> – The pattern the output should be checked for.</li>
<li><strong>timeout</strong> (<em>int</em>) – How many seconds should be waited for the output.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>The pattern argument may be a string, a compiled regular expression,
or a list of any of those types. Strings will be compiled into regular expressions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The index into the pattern list. If the pattern was not a list, it returns 0 on a successful match.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">int</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><code class="xref py py-exc docutils literal"><span class="pre">TimeoutException</span></code> – The output did not match within the given time frame.</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">TerminationException</span></code> – The program terminated before producing the output.</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">NestedException</span></code> – An internal problem occured while waiting for the output.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.running.RunningProgram.get_exitstatus">
<code class="descname">get_exitstatus</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.running.RunningProgram.get_exitstatus" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the exit status of the program execution.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><dl class="docutils">
<dt>Exit status as reported by the operating system,</dt>
<dd>or None if it is not available.</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.running.RunningProgram.get_output">
<code class="descname">get_output</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.running.RunningProgram.get_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the program output produced so far.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Program output as text. May be incomplete.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">str</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="opensubmitexec.running.RunningProgram.sendline">
<code class="descname">sendline</code><span class="sig-paren">(</span><em>text</em><span class="sig-paren">)</span><a class="headerlink" href="#opensubmitexec.running.RunningProgram.sendline" title="Permalink to this definition">¶</a></dt>
<dd><p>Sends an input line to the running program, including os.linesep.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>text</strong> (<em>str</em>) – The input text to be send.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><code class="xref py py-exc docutils literal"><span class="pre">TerminationException</span></code> – The program terminated before / while / after sending the input.</li>
<li><code class="xref py py-exc docutils literal"><span class="pre">NestedException</span></code> – An internal problem occured while waiting for the output.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2017, Peter Tröger.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.6.<br/>
    </p>
  </div>
</footer>
  </body>
</html>